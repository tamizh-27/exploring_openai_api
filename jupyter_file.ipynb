{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NJZ9-IulJeFS"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#pip install openai"
      ],
      "metadata": {
        "id": "oFTwA-H-SJ1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuoIWo8xEa2M"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "# Set API key\n",
        "apiKey = ''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=apiKey)"
      ],
      "metadata": {
        "id": "aNJwZNpmEhRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query based chatbot"
      ],
      "metadata": {
        "id": "NJZ9-IulJeFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Be a chatbot\"}, # <-- This is the system message that provides context to the model\n",
        "    {\"role\": \"user\", \"content\": \"what is your name\"}  # <-- This is the user message for which the model will generate a response\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(\"Assistant: \" + completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDFI6D-MGdTz",
        "outputId": "18d30be4-acc4-4cbc-e941-a127b9320880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant: I'm an artificial intelligence created by OpenAI, so I don't have a personal name. You can call me Assistant or anything else you prefer! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Doctor's prescription information (by passing image URL)"
      ],
      "metadata": {
        "id": "sc4h9hfKJX2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url1 = \"https://www.madeformedical.com/wp-content/uploads/2018/07/vio-4.jpg\"\n",
        "url2 = \"https://th.bing.com/th/id/R.4d7e3ebbb7d2d982e8fe8cb6242aa70b?rik=dsUP6O32ZKA9cQ&riu=http%3a%2f%2f4.bp.blogspot.com%2f-_kBJT0h6Spg%2fUdbTldpNbdI%2fAAAAAAAAAWA%2f18wS5P6bDY4%2fs1600%2fvio-2.jpg&ehk=cnM9pl81usi2T3Fq3VBI9F90axtopr9YgIUnk0i%2fM%2bk%3d&risl=&pid=ImgRaw&r=0\"\n",
        "url3 = \"https://th.bing.com/th/id/R.e2182d84abc48a742a67cd5053eeabec?rik=n%2fhMPZTI9C%2fhaw&riu=http%3a%2f%2f1.bp.blogspot.com%2f-cTmBQ9FDXzE%2fUdbThwAqACI%2fAAAAAAAAAV4%2fPlFvNhgbsms%2fs1600%2fimp-9.jpg&ehk=xEzD7DzVbQGOMLaYcWNDBPpGlcsqPLAWAP9EFQAkM%2b0%3d&risl=&pid=ImgRaw&r=0\"\n",
        "url4 = \"https://th.bing.com/th/id/R.494f6318db8f8520652685f45fa74d74?rik=1fAjzXpLcC220g&riu=http%3a%2f%2f3.bp.blogspot.com%2f-QpPtB0KLvOU%2fUdbT2Lwi06I%2fAAAAAAAAAWw%2ftxvQfySs4Gw%2fs1600%2fvio-6.jpg&ehk=DNJWVpwzutGjSYe4URvpDPowcIe629uwH8eeXm%2bVaFM%3d&risl=&pid=ImgRaw&r=0\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-4o',\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"text\", \"text\": \"what is given in this prescription?\"},\n",
        "            {\"type\": \"image_url\", \"image_url\": {\n",
        "                \"url\": url4}\n",
        "            }\n",
        "        ]}\n",
        "    ],\n",
        "    temperature=0.0,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o06m86YG9d6",
        "outputId": "24fbb805-5ce6-4f09-aba0-0a2b7615c280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prescription appears to be for a medication called \"Amlodipine\" (brand name \"Norvasc\"). The instructions indicate to take one tablet twice a day (BID). The quantity prescribed is 30 tablets.\n",
            "\n",
            "Here is a breakdown of the prescription:\n",
            "\n",
            "- Medication: Amlodipine (Norvasc)\n",
            "- Quantity: #30\n",
            "- Instructions: Take 1 tablet BID (twice a day)\n",
            "\n",
            "The prescription is dated 4-18-12 and includes the patient's name, address, age, sex, and the physician's signature and license numbers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ancient English script"
      ],
      "metadata": {
        "id": "pwpclWdbpK4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url1 = \"https://mymodernmet.com/wp/wp-content/uploads/2018/11/old-english-manuscripts-1-611x1024.jpg\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-4o',\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"text\", \"text\": \"what is written in the image?\"},\n",
        "            {\"type\": \"image_url\", \"image_url\": {\n",
        "                \"url\": url1}\n",
        "            }\n",
        "        ]}\n",
        "    ],\n",
        "    temperature=0.0,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-IXQBa5pSUp",
        "outputId": "4e081a46-7357-4a90-d577-ca93fbcbe215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text in the image is the opening passage of the Old English epic poem \"Beowulf.\" Here is a transcription of the text:\n",
            "\n",
            "```\n",
            "HWÆT. WE GARDE\n",
            "na in geardagum, þeod cyninga,\n",
            "þrym gefrunon, hu ða æþelingas\n",
            "ellen fremedon. Oft Scyld Scefing\n",
            "sceaþena þreatum, monegum mægþum,\n",
            "meodosetla ofteah, egsode eorlas.\n",
            "Syððan ærest wearð feasceaft funden,\n",
            "he þæs frofre gebad, weox under wolcnum,\n",
            "weorðmyndum þah, oþþæt him æghwylc\n",
            "þara ymbsittendra ofer hronrade hyran scolde,\n",
            "gomban gyldan. þæt wæs god cyning.\n",
            "```\n",
            "\n",
            "This passage translates to:\n",
            "\n",
            "```\n",
            "Lo, the Spear-Danes' glory through splendid achievements\n",
            "The folk-kings' former fame we have heard of,\n",
            "How princes displayed then their prowess-in-battle.\n",
            "Oft Scyld the Scefing from enemy hosts\n",
            "From many a people their mead-benches tore.\n",
            "Since first he found him friendless and wretched,\n",
            "The earl had had terror: comfort he got for it,\n",
            "Waxed 'neath the welkin, world-honor gained,\n",
            "Till all his neighbors o'er sea were compelled to\n",
            "Bow to his bidding and bring him their tribute:\n",
            "An excellent atheling! After was borne him\n",
            "A son and heir, young in his dwelling,\n",
            "Whom God-Father sent to solace the people.\n",
            "```\n",
            "\n",
            "This is the beginning of the story of Beowulf, a hero of the Geats, who comes to the aid of Hrothgar, the king of the Danes, whose great hall, Heorot, is plagued by the monster Grendel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### French letter extraction"
      ],
      "metadata": {
        "id": "_e8gygw7jw6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url1 = \"https://th.bing.com/th/id/OIP.pGNSeRtpHfrThZ-j9SU1_gHaEN?rs=1&pid=ImgDetMain\"\n",
        "url2 = \"https://th.bing.com/th/id/OIP.2YNWJXIC4cIUqrYtv4GjcQHaLX?rs=1&pid=ImgDetMain\"\n",
        "url3 = \"https://th.bing.com/th/id/OIP.zEvhMIzNXEDjbGpf5M4u2QAAAA?rs=1&pid=ImgDetMain\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-4o',\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"text\", \"text\": \"extract the text from the image and translate it to english and how many tokens in the input and the output?\"},\n",
        "            {\"type\": \"image_url\", \"image_url\": {\n",
        "                \"url\": url3}\n",
        "            }\n",
        "        ]}\n",
        "    ],\n",
        "    temperature=0.0,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVN-SnQsjqQr",
        "outputId": "d2f6c64e-cf36-42d1-fe91-9a4ba0b08e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the extracted text from the image:\n",
            "\n",
            "```\n",
            "Entre les soussignés\n",
            "Pierre Paul Frédéric Gossard, négociant demeurant à\n",
            "Bordeaux, d'une part, et Pierre Hyacinthe Constant, proprié-\n",
            "taire, demeurant à Bordeaux, d'autre part, il a été\n",
            "convenu ce qui suit.\n",
            "Le sieur Gossard cède pour les produits à faire de\n",
            "lait à large, sur trois années consécutives, que le sieur Constant\n",
            "s'oblige à livrer, et ce, à partir du premier Janvier prochain, et pour\n",
            "finir le trente un Décembre mil huit cent trente trois, au dit\n",
            "sieur Gossard, qui s'oblige à les accepter, au prix de trois francs\n",
            "cinquante centimes le litre, payable mensuellement.\n",
            "Fait à Bordeaux, entre les parties, le premier Octobre mil huit\n",
            "cent trente.\n",
            "Signé : Gossard, Constant.\n",
            "```\n",
            "\n",
            "Translation to English:\n",
            "\n",
            "```\n",
            "Between the undersigned\n",
            "Pierre Paul Frédéric Gossard, merchant residing in\n",
            "Bordeaux, on the one hand, and Pierre Hyacinthe Constant, owner,\n",
            "residing in Bordeaux, on the other hand, it has been\n",
            "agreed as follows.\n",
            "Mr. Gossard transfers for the products to be made from\n",
            "milk in bulk, over three consecutive years, which Mr. Constant\n",
            "agrees to deliver, starting from the first of January next, and ending\n",
            "on the thirty-first of December eighteen thirty-three, to the said\n",
            "Mr. Gossard, who agrees to accept them, at the price of three francs\n",
            "fifty centimes per liter, payable monthly.\n",
            "Done in Bordeaux, between the parties, on the first of October eighteen\n",
            "thirty.\n",
            "Signed: Gossard, Constant.\n",
            "```\n",
            "\n",
            "Token count:\n",
            "- Input (French text): 186 tokens\n",
            "- Output (English translation): 160 tokens\n",
            "\n",
            "Note: The token count is based on the standard tokenization used in natural language processing, where tokens can be words, punctuation marks, or other meaningful elements.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### French leave letter (my handwriting)"
      ],
      "metadata": {
        "id": "jP7vycQp1c7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "\n",
        "IMAGE_PATH = \"french_letter_hw.jpg\"\n",
        "\n",
        "# Open the image file and encode it as a base64 string\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "base64_image = encode_image(IMAGE_PATH)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"text\", \"text\": \"extract the text from the image and translate it to english and how many tokens in the input and the output?\"},\n",
        "            {\"type\": \"image_url\", \"image_url\": {\n",
        "                \"url\": f\"data:image/png;base64,{base64_image}\"}\n",
        "            }\n",
        "        ]}\n",
        "    ],\n",
        "    temperature=0.0,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpMLJRLAxf30",
        "outputId": "c43cd0e7-038b-4f4e-d3f7-a36f6d14ed4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Extracted Text:**\n",
            "```\n",
            "Cher Harsha,\n",
            "\n",
            "Je vous écris pour vous informer que, pour des raisons personnelles, je dois prendre un congé du 15 juin au 30 juin. Pendant cette période, je ne pourrai pas assister au travail et remplir mes responsabilités.\n",
            "\n",
            "Je m'excuse pour tout inconvénient que cela pourrait causer et je veillerai à ce que toutes les tâches en attente soient complétées ou déléguées avant mon départ. Je resterai également disponible par e-mail à harsha@harshagirajlalwani@mobiussonics.in pour toute question urgente pouvant survenir pendant mon absence.\n",
            "\n",
            "Je vous remercie de votre compréhension et de votre coopération.\n",
            "```\n",
            "\n",
            "**Translation to English:**\n",
            "```\n",
            "Dear Harsha,\n",
            "\n",
            "I am writing to inform you that, for personal reasons, I need to take leave from June 15 to June 30. During this period, I will not be able to attend work and fulfill my responsibilities.\n",
            "\n",
            "I apologize for any inconvenience this may cause and I will ensure that all pending tasks are completed or delegated before my departure. I will also remain available by email at harsha@harshagirajlalwani@mobiussonics.in for any urgent questions that may arise during my absence.\n",
            "\n",
            "Thank you for your understanding and cooperation.\n",
            "```\n",
            "\n",
            "**Token Count:**\n",
            "\n",
            "For the input (French text):\n",
            "- The input text has 144 tokens.\n",
            "\n",
            "For the output (English translation):\n",
            "- The output text has 128 tokens.\n",
            "\n",
            "Token counts are approximate and can vary slightly depending on the tokenization method used.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph Insights"
      ],
      "metadata": {
        "id": "-F4BgyD9jrwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# line plot\n",
        "url2 = \"https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/924/2015/09/25200247/CNX_CAT_Figure_02_01_006.jpg\"\n",
        "url3 = \"https://www.ncss.com/wp-content/uploads/2016/05/Scatter-Plot-with-Error-Bars.png\"\n",
        "# pie chart\n",
        "url4 = \"https://media.geeksforgeeks.org/wp-content/uploads/20220608160916/Fig209.jpg\"\n",
        "url5 = \"https://machinelearninggeek.com/wp-content/uploads/2020/10/image-37.png\"\n",
        "# bar graph\n",
        "url6 = \"https://www.vedantu.com/seo/content-images/7c3d520a-0d28-4d6e-967f-7edce54c71b6.png\"\n",
        "url7 = \"https://png.pngtree.com/png-clipart/20220612/original/pngtree-bar-chart-graph-diagram-infographic-element-template-png-image_7966552.png\"\n",
        "# histogram\n",
        "url8 = \"https://python-charts.com/en/distribution/histogram-matplotlib_files/figure-html/histogram-matplotlib.png\"\n",
        "url9 = \"https://h-o-m-e.org/wp-content/uploads/2023/01/bell_curve_1673950763.png\"\n",
        "# box plot\n",
        "url10 = \"https://th.bing.com/th/id/R.8ba46b6ca5b31a98b8ed2e556ca21ca0?rik=ffxKU7MKmer4Ig&riu=http%3a%2f%2forigineditorial.com%2fwp-content%2fuploads%2f2022%2f11%2fFigure-7-Box-plots-688x1024.jpg&ehk=ft0HQ8TB97GyLt5KCykNJazVnV2IkBTDAaldmXNDUzs%3d&risl=&pid=ImgRaw&r=0\"\n",
        "# scatter plot\n",
        "url11 = \"https://www.researchgate.net/publication/365799184/figure/fig5/AS:11431281103472864@1669694377487/The-scatter-plot-of-data-set-with-two-classes-The-data-points-are-generated-with-two.png\"\n",
        "url12 = \"https://kandadata.com/wp-content/uploads/2022/05/2.-Output-Scatterplot-ke-1-1024x742.jpg\"\n",
        "# 3d plot\n",
        "url13 = \"https://user-images.githubusercontent.com/5026621/30236053-bb1ecdbe-94df-11e7-9c5a-9085b8ecac72.png\"\n",
        "# heatmap\n",
        "url14 = \"https://miro.medium.com/max/1400/1*5rXFpjSndFsmCKjYiN2GNw.png\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-4o',\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Help me with my math homework!\"},\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"text\", \"text\": \"give me the dataframe for the graph\"},\n",
        "            {\"type\": \"image_url\", \"image_url\": {\n",
        "                \"url\": url13}\n",
        "            }\n",
        "        ]}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf3arbbuI7fS",
        "outputId": "fa6d92ef-44fc-44c1-f244-e75629d30a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To create a dataframe that represents the data shown in the graph, you can use a structure where you have columns for \"Fraction of cells initially alive\", \"Grid size\", and \"Average number of generations\". This will allow you to represent the 3D bar chart in a table format. Here's an example dataframe structure using pandas in Python:\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "\n",
            "data = {\n",
            "    'Fraction of cells initially alive': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
            "    'Grid size 5x5': [0, 5, 10, 20, 30, 40, 50, 60, 50, 20, 10],\n",
            "    'Grid size 6x6': [1, 8, 15, 22, 35, 45, 60, 70, 65, 25, 15],\n",
            "    'Grid size 7x7': [2, 10, 20, 30, 40, 50, 70, 80, 75, 30, 17],\n",
            "    'Grid size 8x8': [3, 12, 25, 35, 45, 55, 75, 90, 80, 35, 19],\n",
            "    'Grid size 9x9': [4, 15, 30, 40, 50, 60, 80, 100, 85, 40, 20],\n",
            "    'Grid size 10x10': [5, 18, 35, 45, 55, 65, 90, 110, 90, 45, 22],\n",
            "    'Grid size 11x11': [6, 20, 40, 50, 60, 75, 95, 120, 100, 50, 24],\n",
            "    'Grid size 12x12': [7, 22, 45, 55, 65, 85, 100, 125, 105, 55, 25],\n",
            "    'Grid size 13x13': [8, 25, 50, 60, 70, 90, 110, 130, 110, 60, 27],\n",
            "    'Grid size 14x14': [9, 27, 55, 65, 75, 95, 115, 135, 115, 65, 28],\n",
            "    'Grid size 15x15': [10, 30, 60, 70, 80, 100, 120, 140, 120, 70, 30]\n",
            "}\n",
            "\n",
            "df = pd.DataFrame(data)\n",
            "\n",
            "print(df)\n",
            "```\n",
            "\n",
            "This is an illustrative example as the exact numbers may differ; you should replace them with the values from your graph. The dataframe shows the number of generations until stabilization for different initial cell populations and grid sizes. Each column after \"Fraction of cells initially alive\" represents the data for a specific grid size. The values are hypothetical and should be replaced with the exact values from the graph.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wMH2oT3dkMKJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}